{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd3424e-d856-4423-878c-48f920f94e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "from pyarrow import parquet as pq\n",
    "from pyarrow import fs\n",
    "\n",
    "# üîê lakeFS credentials\n",
    "ACCESS_KEY = \"access_key\"\n",
    "SECRET_KEY = \"secret_key\"\n",
    "lakefs_endpoint = \"http://lakefs-dev:8000/\"\n",
    "\n",
    "# ‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ FileSystem ‡∏Ç‡∏≠‡∏á LakeFS\n",
    "s3 = fs.S3FileSystem(\n",
    "    access_key=ACCESS_KEY, \n",
    "    secret_key=SECRET_KEY, \n",
    "    endpoint_override=lakefs_endpoint\n",
    ")\n",
    "\n",
    "# ‚úÖ ‡∏£‡∏∞‡∏ö‡∏∏ Path ‡∏´‡∏•‡∏±‡∏Å\n",
    "base_path = 'weather/main/weather.parquet/year=2025/month=5/'\n",
    "\n",
    "# ‚úÖ ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "days = [12, 13, 14, 15]\n",
    "\n",
    "# ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á List ‡πÄ‡∏Å‡πá‡∏ö DataFrame\n",
    "df_list = []\n",
    "\n",
    "# ‚úÖ ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ß‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏°‡πÄ‡∏õ‡πá‡∏ô DataFrame\n",
    "for day in days:\n",
    "    path = f\"{base_path}day={day}/\"\n",
    "    print(f\"Loading data from: {path}\")\n",
    "    \n",
    "    # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Parquet\n",
    "    dataset = pq.ParquetDataset(path, filesystem=s3)\n",
    "    \n",
    "    # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Schema ‡∏Ç‡∏≠‡∏á dataset\n",
    "    schema = dataset.schema\n",
    "    \n",
    "    # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á Schema ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô float64 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô float32 ‡∏´‡∏£‡∏∑‡∏≠ int64\n",
    "    fields = []\n",
    "    for i in range(len(schema)):\n",
    "        field = schema.field(i)\n",
    "        if isinstance(field.type, pa.FloatArray) or field.type == pa.float32():\n",
    "            fields.append(pa.field(field.name, pa.float64()))  # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô float64\n",
    "        elif field.type == pa.int64():  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏ô‡∏¥‡∏î int64\n",
    "            fields.append(pa.field(field.name, pa.float64()))  # ‡πÅ‡∏õ‡∏•‡∏á int64 ‡πÄ‡∏õ‡πá‡∏ô float64\n",
    "        else:\n",
    "            fields.append(field)\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Schema ‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å fields ‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß\n",
    "    new_schema = pa.schema(fields)\n",
    "    \n",
    "    # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô DataFrame\n",
    "    try:\n",
    "        table = dataset.read().cast(new_schema)\n",
    "        df = table.to_pandas()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {path}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° DataFrame ‡∏•‡∏á‡πÉ‡∏ô List\n",
    "    df_list.append(df)\n",
    "\n",
    "# ‚úÖ ‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å DataFrame ‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô\n",
    "final_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "print(final_df.info())\n",
    "print(final_df.head())\n",
    "print(f\"Total Records Loaded: {len(final_df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
